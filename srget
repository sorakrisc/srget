#!/usr/bin/env python
import sys
import socket as skt
from urlparse import urlparse
import os
import threading

def make_request(req_type, what, details, ver="1.1"):
    """ Compose an HTTP request """
    NL = "\r\n"
    req_line = "{verb} {w} HTTP/{v}".format(verb=req_type, w=what, v=ver)
    details = ["{name}: {v}".format(name=n,v=v) for (n,v) in details.iteritems()]
    detail_lines = NL.join(details)
    full_request = "".join([req_line, NL, detail_lines, NL, NL])
    return full_request

def parse_url(url, DEFAULT_PORT=80):
    """ Parse a given url into host, path, and port.
        Use DEFAULT_PORT (80) if unspecified.
    """
    parsed_url = urlparse(url)
    host, path, port = (parsed_url.hostname,
                        parsed_url.path,
                        parsed_url.port)
    if not port:
        port = DEFAULT_PORT
    return (host, path, port)

def parse_argv(argv):
    """ Parse sys.argv into downloader, open_command, output_filename,
        concurr_command, num_concurr, and url
        if command is invalid return None
    """
    #checkpoint 3 -c have to add
    concurr_command = None
    num_concurr = 1
    downloader = argv[0]
    if argv[1]=="-o":
        open_command = argv[1]
        output_filename = argv[2]
        if "-c" == argv[3] and len(argv)==6:
            concurr_command = argv[3]
            num_concurr = argv[4]
            if "http://" in argv[5]:
                url = argv[5]
            else:
                url = "http://"+argv[5]
        elif "-c" == argv[3] and len(argv)==5:
            concurr_command = argv[3]
            num_concurr = 5
            if "http://" in argv[4]:
                url = argv[4]
            else:
                url = "http://"+argv[4]
        else:
            if "http://" in argv[3]:
                url = argv[3]
            else:
                url = "http://"+argv[3]
        return (downloader, open_command, output_filename, concurr_command, num_concurr,  url)
    else:
        return None

def createDownloadThread(output_filename, num_concurr, r, end, url):
    """Create download thread"""
    thrd = HTTPClient(output_filename, num_concurr, r, end, url)
    download_thread= threading.Thread(target=thrd.main())
    download_thread.start()

def check_cache_file(temp_file_lst):
    """check if there is a lost of connection in either one of the thread"""
    for f in temp_file_lst:
        if os.path.isfile(f+"_cache"+".txt"):
            return True
    return False

def merge_files(output_filename, temp_file_lst):
    """ concatenate multiple files together
        and delete the file that is already merged
    """
    with open(output_filename, 'w') as f:
        for fname in temp_file_lst:
            with open(fname) as infile:
                for line in infile:
                    f.write(line)
            os.remove(os.getcwd()+"/"+fname)


class HTTPClient(object):
    ## Size of the buffer for each recv

    def __init__(self, output_filename, num_concurr, startpoint, endpoint, url):
        object.__init__(self)
        host, path, port = parse_url(url)
        self.RECV_CHUNK_SIZE = 8192

        # Create a TCP socket to thost at the right port
        self.client_socket = skt.socket(skt.AF_INET, skt.SOCK_STREAM)
        self.client_socket.connect((host, port))

        self.output_filename = output_filename
        if "temp" in output_filename:
            self.num_temp =int(output_filename[:output_filename.find("_")])
        else:
            self.num_temp = 1
        self.num_concurr = int(num_concurr)

        self.url = url
        self.host = host
        self.path = path
        self.port = port

        # all the global var
        self.byte_count = 0
        self.resume_status = False
        self.data =""
        self.ini_header={}
        self.content = ""
        self.content_length= 0
        self.startpoint = startpoint
        self.endpoint = endpoint

        # self.main()

    def check_Resume_Status(self):
        """set a boolean variable if the cache file exsist"""
        self.resume_status = os.path.isfile(self.output_filename+"_cache"+".txt")
    def send_resume_request(self):
        """Generate request in range of bytes using make_request() and send request
            resume: send range of byte, concurrent: send range of byte calculated,
            and normal: sending initial request
        """
        if self.num_concurr==1:
            # Make a range request & deliver it
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+'Range: bytes='+str(self.byte_count)+'-'}
            )
            self.client_socket.send(request)
        # tail file : range ()
        elif self.num_concurr==self.num_temp:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str((self.startpoint*(self.num_temp-1)) + self.byte_count)+
                 '-'+str(self.endpoint-1)}
            )
            self.client_socket.send(request)
        # head file
        elif self.num_temp==1:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str(self.byte_count)+
                 '-'+str((self.num_temp * self.startpoint))}
            )
            self.client_socket.send(request)
        # middle files
        else:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str((self.startpoint*(self.num_temp-1))+self.byte_count)+
                 '-'+str((self.num_temp * self.startpoint)+1)}
            )
            self.client_socket.send(request)


    def send_request(self):
        """Generate request using make_request() and send request
            resume: send range of byte, concurrent: send range of byte calculated,
            and normal: sending initial request
        """
        # if the there is a cache file send the request with an initial byte
        # first one
        if self.num_concurr>1 and self.num_temp==1:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str((self.num_temp - 1 ) * self.startpoint)+
                 '-'+str(self.num_temp * self.startpoint)}
            )
            self.client_socket.send(request)
        # resume status is false and there is a num_concurr
        elif self.num_concurr>1 and self.num_concurr!=self.num_temp:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str(((self.num_temp - 1 ) * self.startpoint)+1)+
                 '-'+str(self.num_temp * self.startpoint)}
            )
            self.client_socket.send(request)
        # last one
        elif self.num_concurr>1 and self.num_concurr==self.num_temp:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str(((self.num_temp - 1 ) * self.startpoint)+1)+'-'}
            )
            self.client_socket.send(request)
        # if the cache is not there send the normal request
        else:
            # Make an initial request & deliver it
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'}
            )
            self.client_socket.send(request)

    def recv_data(self):
        """Receive data froom the socket and store in self.data"""
        self.data = self.client_socket.recv(self.RECV_CHUNK_SIZE)

    def get_content_length(self):
        self.send_request()
        self.get_header()
        return int(self.ini_header["Content-Length"])

    def get_header(self):
        """ Extract header from the recv_data()
            then split the content from the header
            and store all the header in a dictionary
        """
        self.recv_data()
        header_str, self.content = self.data.split("\r\n\r\n")
        for e in header_str.split("\r\n"):
            if ":" in e:
                key, value = e.split(": ")
                self.ini_header[key] = value

    def write_cache(self):
        """Create and write a cache file when download is interrupt
            Writing 1. ETag 2. Last-Modified 3. Content-Length 4. byte_count
        """
        with open(self.output_filename+"_cache"+".txt", 'wb') as cache:
            cache.write("byte_count: "+str(self.byte_count)+"\r\n")
            if self.ini_header.has_key("ETag"):
                cache.write("ETag: "+self.ini_header["ETag"]+"\r\n")
            if self.ini_header.has_key("Last-Modified"):
                cache.write("Last-Modified: "+self.ini_header["Last-Modified"]+"\r\n")
            if self.ini_header.has_key("Content-Length"):
                cache.write("Content-Length: "+str(self.content_length)+"\r\n")


    def extract_cache(self):
        """Extract data from the cache file"""
        try:
            with open(self.output_filename+"_cache"+".txt", "r")  as cache:
                cache_data = cache.read()
                cache_dict={}
                for e in cache_data.split("\r\n"):
                    if ":" in e:
                        key, value = e.split(": ")
                        cache_dict[key]=value
                if cache_dict.has_key("ETag"):
                    self.ETag = cache_dict["ETag"]
                if cache_dict.has_key("Last-Modified"):
                    self.Last_Modified = cache_dict["Last-Modified"]
                if cache_dict.has_key("Content-Length"):
                    self.content_length = int(cache_dict["Content-Length"])
                    # print "from extract: " + cache_dict["Content-Length"]
                if cache_dict.has_key("byte_count"):
                    self.byte_count = int(cache_dict["byte_count"])
        except IOError, KeyboardInterrupt:
            print "There is a lost of connenction"

    def handle_load_write_data(self, f):
        try :
            while self.byte_count<self.content_length:
                self.recv_data()
                f.write(self.data)
                if len(self.data)+self.byte_count==self.content_length:
                    self.byte_count+=len(self.data)
                    self.client_socket.close()
                    # print "lllll "+self.output_filename +" "+str(self.byte_count)+" "+str(self.content_length)
                    break
                self.byte_count+=len(self.data)
                # print self.output_filename +" "+str(self.byte_count)+" "+str(self.content_length)
        except KeyboardInterrupt, IOError:
            ## **** Neeed to save endpoint and detail to continue download
            print "There is a lost of connenction"
            self.write_cache()

    def write_file(self):
        if self.ini_header.has_key("Content-Length") and not self.resume_status:
            with open(self.output_filename, 'wb') as f:
                self.content_length = int(self.ini_header["Content-Length"])
                self.byte_count+=len(self.content)
                #write the remaining content
                f.write(self.content)
                #load and write data
                # print "Content-Length"+str(self.content_length)
                self.handle_load_write_data(f)
        elif self.ini_header.has_key("Content-Length") and self.resume_status:
            with open(self.output_filename, 'a+') as f:
                os.remove(os.getcwd()+"/"+self.output_filename+"_cache.txt")
                self.byte_count+=len(self.content)
                #write the remaining content
                f.write(self.content)
                #load and write data
                self.handle_load_write_data(f)
            #***if mai mee contentlen... tum ngai wa

    def main(self):
        self.check_Resume_Status()
        if (os.path.isfile(self.output_filename) and not self.resume_status):
            print self.output_filename+ " already exsist"

        #if resume status is false
        elif not self.resume_status:
            self.send_request()
            #get header"
            self.get_header()
            #load and write file
            self.write_file()
            #print "Download complete: "+self.output_filename
        # if cache file  exsist
        else:
            self.extract_cache()
            self.send_resume_request()
            self.get_header()
            self.write_file()
            #print "Download complete: "+self.output_filename


if __name__ == "__main__":
    if parse_argv(sys.argv) != None:
        downloader, open_command, output_filename, concurr_command, num_concurr, url = parse_argv(sys.argv)
        # **inefficient if there is a resume then u dont have to request for content_length again
        cont_length=HTTPClient(output_filename, 1, 1, 1, url).get_content_length()
        r= cont_length/int(num_concurr)
        # print "totalcont_length:"+ str(cont_length)
        # print "num_concurr: "+str(num_concurr)
        # print "Range: "+str(r)
        if (open_command =="-o") and  (concurr_command=="-c"):
            temp_file_lst=[]
            for i in range(1,int(num_concurr)+1):
                temp_file= str(i)+"_temp_"+output_filename
                temp_file_lst.append(temp_file)
                createDownloadThread(temp_file, num_concurr, r, cont_length, url)

            if not check_cache_file(temp_file_lst):
                #merge file void function
                merge_files(output_filename, temp_file_lst)


        else:
            HTTPClient(output_filename, num_concurr, r, cont_length, url).main()
    else:
        print "Invalid Command"
