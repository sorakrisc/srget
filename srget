#!/usr/bin/env python
import sys
import socket as skt
from urlparse import urlparse
import os
import threading

def make_request(req_type, what, details, ver="1.1"):
    """ Compose an HTTP request """
    NL = "\r\n"
    req_line = "{verb} {w} HTTP/{v}".format(verb=req_type, w=what, v=ver)
    details = ["{name}: {v}".format(name=n,v=v) for (n,v) in details.iteritems()]
    detail_lines = NL.join(details)
    full_request = "".join([req_line, NL, detail_lines, NL, NL])
    return full_request

def parse_url(url, DEFAULT_PORT=80):
    """ Parse a given url into host, path, and port.
        Use DEFAULT_PORT (80) if unspecified.
    """
    parsed_url = urlparse(url)
    host, path, port = (parsed_url.hostname,
                        parsed_url.path,
                        parsed_url.port)
    if not port:
        port = DEFAULT_PORT
    return (host, path, port)

def parse_argv(argv):
    """ Parse sys.argv into downloader, open_command, output_filename,
        concurr_command, num_concurr, and url
        if command is invalid return None
    """
    #checkpoint 3 -c have to add
    concurr_command = None
    num_concurr = 1
    downloader = argv[0]
    if argv[1]=="-o":
        open_command = argv[1]
        output_filename = argv[2]
        if "-c" == argv[3] and len(argv)==6:
            concurr_command = argv[3]
            num_concurr = argv[4]
            if "http://" in argv[5]:
                url = argv[5]
            else:
                url = "http://"+argv[5]
        elif "-c" == argv[3] and len(argv)==5:
            concurr_command = argv[3]
            num_concurr = 5
            if "http://" in argv[4]:
                url = argv[4]
            else:
                url = "http://"+argv[4]
        else:
            if "http://" in argv[3]:
                url = argv[3]
            else:
                url = "http://"+argv[3]
        return (downloader, open_command, output_filename, concurr_command, num_concurr,  url)
    else:
        return None

def check_cache_file(temp_file_lst):
    """check if there is a lost of connection in either one of the thread"""
    for f in temp_file_lst:
        if os.path.isfile(f+"_cache"+".txt"):
            return True
    return False

def merge_files(output_filename, temp_file_lst):
    """ concatenate multiple files together
        and delete the file that is already merged
    """
    try:
        with open(output_filename, 'w') as f:
            for fname in temp_file_lst:
                with open(fname) as infile:
                    for line in infile:
                        f.write(line)
                os.remove(os.getcwd()+"/"+fname)
    except IOError, KeyboardInterrupt:
        print "There is a lost of connenction: Have to redownload everythin"

def extract_cache(output_filename):
    """Extract data from the cache file"""
    with open(output_filename, "r")  as cache:
        cache_data = cache.read()
        cache_dict={}
        for e in cache_data.split("\r\n"):
            if ":" in e:
                key, value = e.split(": ")
                cache_dict[key]=value
    return cache_dict

class HTTPClient(object):
    ## Size of the buffer for each recv

    def __init__(self, output_filename, num_concurr, startpoint, endpoint, url):
        object.__init__(self)
        host, path, port = parse_url(url)
        self.RECV_CHUNK_SIZE = 8192

        # Create a TCP socket to thost at the right port
        self.client_socket = skt.socket(skt.AF_INET, skt.SOCK_STREAM)
        self.client_socket.connect((host, port))

        self.output_filename = output_filename
        if "temp" in output_filename:
            self.num_temp =int(output_filename[:output_filename.find("_")])
        else:
            self.num_temp = 1
        self.num_concurr = int(num_concurr)

        self.url = url
        self.host = host
        self.path = path
        self.port = port

        # all the global var
        self.byte_count = 0
        self.resume_status = False
        self.data =""
        self.ini_header={}
        self.content = ""
        self.content_length= 0
        self.startpoint = startpoint
        self.endpoint = endpoint

    def check_Resume_Status(self):
        """set a boolean variable if the cache file exsist"""
        self.resume_status = os.path.isfile(self.output_filename+"_cache"+".txt")
    def send_resume_request(self):
        """Generate request in range of bytes using make_request() and send request
            resume: send range of byte, concurrent: send range of byte calculated,
            and normal: sending initial request
        """
        if self.num_concurr==1:
            # Make a range request & deliver it
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+'Range: bytes='+str(self.byte_count)+'-'}
            )
            self.client_socket.send(request)
        # tail file : range ()
        elif self.num_concurr==self.num_temp:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str((self.startpoint*(self.num_temp-1)) + self.byte_count)+
                 '-'+str(self.endpoint-1)}
            )
            self.client_socket.send(request)
        # head file
        elif self.num_temp==1:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str(self.byte_count)+
                 '-'+str((self.num_temp * self.startpoint))}
            )
            self.client_socket.send(request)
        # middle files
        else:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str((self.startpoint*(self.num_temp-1))+self.byte_count)+
                 '-'+str((self.num_temp * self.startpoint)+1)}
            )
            self.client_socket.send(request)


    def send_request(self):
        """Generate request using make_request() and send request
            resume: send range of byte, concurrent: send range of byte calculated,
            and normal: sending initial request
        """
        # if the there is a cache file send the request with an initial byte
        if self.num_concurr>1 and self.num_temp==1:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str((self.num_temp - 1 ) * self.startpoint)+
                 '-'+str(self.num_temp * self.startpoint)}
            )
            self.client_socket.send(request)
        # resume status is false and there is a num_concurr
        elif self.num_concurr>1 and self.num_concurr!=self.num_temp:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str(((self.num_temp - 1 ) * self.startpoint)+1)+
                 '-'+str(self.num_temp * self.startpoint)}
            )
            self.client_socket.send(request)
        elif self.num_concurr>1 and self.num_concurr==self.num_temp:
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'+'\r\n'+
                 'Range: bytes='+str(((self.num_temp - 1 ) * self.startpoint)+1)+'-'}
            )
            self.client_socket.send(request)
        # if the cache is not there send the normal request
        else:
            # Make an initial request & deliver it
            request = make_request('GET', self.path,
                {'Host': self.host,
                 'Connection': 'close'}
            )
            self.client_socket.send(request)

    def recv_data(self):
        """Receive data froom the socket and store in self.data"""
        self.data = self.client_socket.recv(self.RECV_CHUNK_SIZE)

    def get_etag_lastmod_content_length(self):
        self.send_request()
        self.get_header()

        if self.ini_header.has_key("Content-Length") and self.ini_header.has_key("ETag") and self.ini_header.has_key("Last-Modified"):
            return (int(self.ini_header["Content-Length"]), str(self.ini_header["ETag"]), str(self.ini_header["Last-Modified"]))
        elif self.ini_header.has_key("Content-Length"):
            return (int(self.ini_header["Content-Length"]), None, None)
        else:
            return (None, None, None)
    def get_header(self):
        """ Extract header from the recv_data()
            then split the content from the header
            and store all the header in a dictionary
        """
        self.recv_data()
        header_str, self.content = self.data.split("\r\n\r\n")
        for e in header_str.split("\r\n"):
            if ":" in e:
                key, value = e.split(": ")
                self.ini_header[key] = value

    def write_cache(self):
        """Create and write a cache file when download is interrupt
            Writing 1. ETag 2. Last-Modified 3. Content-Length 4. byte_count
        """
        with open(self.output_filename+"_cache"+".txt", 'wb') as cache:
            cache.write("byte_count: "+str(self.byte_count)+"\r\n")
            if self.ini_header.has_key("ETag"):
                cache.write("ETag: "+self.ini_header["ETag"]+"\r\n")
            if self.ini_header.has_key("Last-Modified"):
                cache.write("Last-Modified: "+self.ini_header["Last-Modified"]+"\r\n")
            if self.ini_header.has_key("Content-Length"):
                cache.write("Content-Length: "+str(self.content_length)+"\r\n")

                    # print "from extract: " + cache_dict["Content-Length"
    def extract_cache(self):
        """Extract data from the cache file"""
        try:
            with open(self.output_filename+"_cache"+".txt", "r")  as cache:
                cache_data = cache.read()
                cache_dict={}
                for e in cache_data.split("\r\n"):
                    if ":" in e:
                        key, value = e.split(": ")
                        cache_dict[key]=value
                if cache_dict.has_key("ETag"):
                    self.ETag = cache_dict["ETag"]
                if cache_dict.has_key("Last-Modified"):
                    self.Last_Modified = cache_dict["Last-Modified"]
                if cache_dict.has_key("Content-Length"):
                    self.content_length = int(cache_dict["Content-Length"])
                if cache_dict.has_key("byte_count"):
                    self.byte_count = int(cache_dict["byte_count"])
        except IOError, KeyboardInterrupt:
            print "There is a lost of connenction"

    def handle_load_write_data(self, f):
        try :
            while self.byte_count<self.content_length:
                self.recv_data()
                f.write(self.data)
                if len(self.data)+self.byte_count==self.content_length:
                    self.byte_count+=len(self.data)
                    self.client_socket.close()
                    break
                self.byte_count+=len(self.data)
        except KeyboardInterrupt, IOError:
            print "There is a lost of connenction"
            self.write_cache()

    def write_file(self):
        if self.ini_header.has_key("Content-Length") and not self.resume_status:
            with open(self.output_filename, 'wb') as f:
                self.content_length = int(self.ini_header["Content-Length"])
                self.byte_count+=len(self.content)
                #write the remaining content
                f.write(self.content)
                #load and write data
                self.handle_load_write_data(f)
        elif self.ini_header.has_key("Content-Length") and self.resume_status:
            with open(self.output_filename, 'a+') as f:
                os.remove(os.getcwd()+"/"+self.output_filename+"_cache.txt")
                self.byte_count+=len(self.content)
                #write the remaining content
                f.write(self.content)
                #load and write data
                self.handle_load_write_data(f)


    def main(self):
        self.check_Resume_Status()
        if (os.path.isfile(self.output_filename) and not self.resume_status):
        #if resume status is false
        elif not self.resume_status:
            self.send_request()
            #get header"
            self.get_header()
            #load and write file
            self.write_file()
        # if cache file  exsist
        else:
            self.extract_cache()
            self.send_resume_request()
            self.get_header()
            self.write_file()

if __name__ == "__main__":
    if parse_argv(sys.argv) != None:
        downloader, open_command, output_filename, concurr_command, num_concurr, url = parse_argv(sys.argv)
        cont_length, etag, lastmod =HTTPClient(output_filename, 1, 1, 1, url).get_etag_lastmod_content_length()
        r= cont_length/int(num_concurr)

        if etag==None and lastmod==None and (os.path.isfile(output_filename+"_cache.txt")):
            os.remove(os.getcwd()+"/"+output_filename+"_cache.txt")
        if (os.path.isfile(output_filename) and not (os.path.isfile(output_filename+"_cache.txt"))):
            print "The file already exsist"
        elif (open_command) != "-o":
            print "Wrong Command"
        elif cont_length==None:
            print "The link is not supported by the program"

        elif concurr_command=="-c":
            temp_file_lst=[]
            thrdList=[]
            for i in range(1,int(num_concurr)+1):
                temp_file= str(i)+"_temp_"+output_filename
                temp_file_lst.append(temp_file)
                thrds = HTTPClient(temp_file, num_concurr, r, cont_length, url)
                thrd= threading.Thread(target=thrds.main())
                thrdList.append(thrd)
                thrd.start()
            for echthrd in thrdList:
                echthrd.join()
            # if there is no cache file merge them
            if not check_cache_file(temp_file_lst):
                # merge file void function
                merge_files(output_filename, temp_file_lst)
        else:
            HTTPClient(output_filename, num_concurr, r, cont_length, url).main()
    else:
        print "Invalid Command"
